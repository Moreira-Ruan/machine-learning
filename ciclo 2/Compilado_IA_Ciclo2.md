
# Compilado Completo - Intelig√™ncia Artificial (Ciclo 2)

Professor: Dr. Henrique Valle de Lima  
Centro Universit√°rio UniEVANG√âLICA

---

## üìñ Sum√°rio
1. Classificadores Baseados em Regras
2. Teorema de Bayes e Naive Bayes
3. Regress√£o Linear Simples
4. C√°lculos Resolvidos (Exerc√≠cios Pr√°ticos)
5. Quest√µes Dissertativas e Respostas

---

## 1Ô∏è‚É£ Classificadores Baseados em Regras

### O que s√£o?
- Modelo do tipo if-then-else que associa condi√ß√µes a uma classe.
- Ex: Se "Gives Birth = yes" e "Body Temperature = warm_blooded" ‚Üí Mammals.

### Constru√ß√£o das Regras
- Geral para Espec√≠fico: Adiciona restri√ß√µes gradativamente.
- Espec√≠fico para Geral: Remove restri√ß√µes para aumentar cobertura.

### M√©tricas
- **Cobertura**: Quantos exemplos a regra cobre.
- **Acur√°cia**: acertos / cobertos pela regra.
- **Laplace**: Estimativa de probabilidade corrigida: (acertos + 1) / (total + |classes|).
- **FOIL's Gain**: Mede informa√ß√£o adicional da regra.

### RIPPER Algorithm
- Indu√ß√£o de regras com poda (pruning).
- Focado em datasets desbalanceados.

---

## 2Ô∏è‚É£ Teorema de Bayes e Naive Bayes

### Teorema de Bayes
- P(H|X) = (P(X|H) * P(H)) / P(X)
- **P(H|X)**: probabilidade a posteriori.
- **P(H)**: probabilidade a priori.
- **P(X|H)**: likelihood.
- **P(X)**: evid√™ncia.

### Naive Bayes
- Assume independ√™ncia condicional dos atributos.
- F√≥rmula: P(C|X) ‚àù P(C) * Œ† P(Xi|C)
- Utilizado em: diagn√≥stico m√©dico, filtragem de spam, classifica√ß√£o de textos.

### Exemplo - Diagn√≥stico de C√¢ncer
- P(H_c) = 0,0002
- P(Positivo|H_c) = 0,95 / P(Positivo|¬¨H_c) = 0,10
- C√°lculo posteriori: P(H_c|Positivo) ‚âà 0,19%

### Interpreta√ß√£o
Mesmo com teste positivo, a baixa preval√™ncia da doen√ßa reduz a chance real de ser um caso verdadeiro.

---

## 3Ô∏è‚É£ Regress√£o Linear Simples

### Conceito
- Modela rela√ß√£o entre vari√°vel dependente (Y) e independente (X).
- F√≥rmula: Y = a + bX

### Correla√ß√£o de Pearson
- Mede for√ßa e dire√ß√£o da rela√ß√£o linear entre X e Y.

### Coeficiente de Determina√ß√£o (R¬≤)
- Mede propor√ß√£o da varia√ß√£o de Y explicada por X.
- Varia de 0 a 1.

### Estima√ß√£o de a e b (M√≠nimos Quadrados)
- Inclina√ß√£o (b): cov(X,Y) / var(X)
- Intercepto (a): YÃÑ - bXÃÑ

---

## 4Ô∏è‚É£ C√°lculos Resolvidos

### Regress√£o: Fertilizante vs Produtividade
- Regress√£o Linear Simples aplicada.
- Y = 2.0667 + 0.0607X
- R¬≤ = 0.998
- Previs√£o para 45kg/ha: 5.06 ton/ha

### Teorema de Bayes - C√¢ncer
- P(Positivo) = 0.10017
- P(H_c|Positivo) ‚âà 0.19%

### Regress√£o: Peso pela Altura
- Ex: Y = -190 + 1.5X
- R¬≤ = 1.0 (dataset artificial simples)
- Previs√£o para 170cm: 70kg

### Regress√£o: Octanagem vs Aditivo
- Y = 85.571 + 1.571X
- R¬≤ = 0.995
- Previs√£o para 5.5% de aditivo: 93.21

---

## 5Ô∏è‚É£ Quest√µes Dissertativas e Respostas

### Q1. Explique o funcionamento do algoritmo RIPPER e suas vantagens em datasets desbalanceados.
**Resposta**:  
O RIPPER √© um algoritmo de indu√ß√£o de regras baseado em cobrir exemplos positivos enquanto minimiza erros em negativos. Ele aplica poda para evitar overfitting e √© robusto em bases desbalanceadas pois otimiza cobertura espec√≠fica por classe, mantendo regras concisas.

### Q2. Em um teste com 90% sensibilidade, 95% especificidade e preval√™ncia de 1%, calcule P(doen√ßa|positivo).
**Resposta**:  
P(H) = 0.01, P(Pos|H) = 0.9, P(Pos|¬¨H) = 0.05  
P(Pos) = (0.9 * 0.01) + (0.05 * 0.99) = 0.009 + 0.0495 = 0.0585  
P(H|Pos) = (0.9 * 0.01) / 0.0585 = 0.009 / 0.0585 ‚âà 15.38%

### Q3. Explique a import√¢ncia do coeficiente de determina√ß√£o (R¬≤) em regress√µes lineares.
**Resposta**:  
O R¬≤ indica a propor√ß√£o da varia√ß√£o da vari√°vel dependente explicada pelo modelo em rela√ß√£o √† vari√°vel independente. Valores pr√≥ximos de 1 indicam forte rela√ß√£o linear e bom ajuste. √â fundamental para validar a qualidade do modelo preditivo.

---

## üîö Fim do Compilado
